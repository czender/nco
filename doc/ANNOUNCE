$Header$ -*-text-*-

netCDF Operators NCO version 5.2.2 sheepishly step forward

http://nco.sf.net (Homepage, Mailing lists, Help)
http://github.com/nco/nco (Source Code, Issues, Releases)

What's new?
Version 5.2.2 fixes an issue with ncremap and ncclimo in MPI mode.
Another small fix to enables GCC compilation in pedantic mode.
No new features are implemented, but it was too late to recall 5.2.0.
My apologies and thanks to the package maintainers.

Work on NCO 5.2.3 has commenced and aims to add support for Zarr S3 
stores, and to polish support for new codecs..

Enjoy,
Charlie

NEW FEATURES (full details always in ChangeLog):

[These just repeat the changes in 5.2.0 since most peopld never used it]

A. ncks can now help analyze initial condition and restart datasets
produced by the E3SM ELM and CESM CLM/CTSM land-surface models.
Whereas gridded history datasets from these ESMs use a standard
gridded data format, these land-surface "restart files" employ a
custom packing format that unwinds multi-dimensional data into
sparse, 1-D (S1D) arrays that are not easily visualized. ncks can
now convert these S1D files into gridded datasets where all dimensions
are explicitly declared (rather than unrolled or "packed"). 
Invoke this conversion feature with the --s1d option and point
ncks to a file that contains the horizontal coordinates (which
restart files do not explicitly contain) and the restart file.
The output file is the fully gridded input file, with no loss
of information:
ncks --s1d --hrz=elmv3_history.nc elmv3_restart.nc out.nc
The output file contains all input variables placed on a lat-lon or 
unstructured grid, with new dimensions for Plant Funtional Type (PFT)
and multiple elevation class (MEC).
http://nco.sf.net/nco.html#s1d

B. ncclimo timeseries mode now supports all input methods (including
automatic filename generation) long-supported by climo mode. Previously
ncclimo (in timeseries mode) had to receive explicit lists of input
files, either from stdin or from the command line. Now ncclimo will
automatically generate the input file list for files that adhere to
common CESM/E3SM naming conventions (usually for monthly average
files). The syntax is identical to that long used in climo mode:
% ncclimo --split -c $caseid -s 2000 -e 2024 -i $drc_in -o $drc_out
http://nco.sf.net/nco.html#ncclimo

C. ncremap supports --alg_lst=alg_lst, a comma-separated list of the
algorithms that MWF-mode uses to create map-files. This option can
be used to shorten or alter the default list, which is 
'esmfaave,esmfbilin,ncoaave,ncoidw,traave,trbilin,trfv2,trintbilin'.
Each name in the list should be the primary name of an algorithm,
not a synonym. For example, use 'esmfaave,traave' not
'aave,fv2fv_flx' (the latter are backward-compatible synonyms
for the former). The algorithm list must be consistent with grid-types
supplied: ESMF algorithms work with meshes in ESMF, SCRIP, or UGRID
formats. NCO algorithms only work with meshes in SCRIP format.
TempestRemap algorithms work with meshes in ESMF, Exodus, SCRIP, or
UGRID formats. On output, ncremap inserts each algorithm name into the 
output map-file name in this format: map_src_to_dst_alg.date.nc.
For example,
% ncremap -P mwf --alg_lst=esmfnstod,ncoaave,ncoidw,traave,trbilin \
  -s ocean.QU.240km.scrip.181106.nc -g ne11pg2.nc --nm_src=QU240 \
  --nm_dst=ne11pg2 --dt_sng=20240201
...
% ls map*
map_QU240_to_ne11pg2_esmfnstod.20240201.nc
map_QU240_to_ne11pg2_ncoaave.20240201.nc
map_QU240_to_ne11pg2_ncoidw.20240201.nc
map_QU240_to_ne11pg2_traave.20240201.nc
map_QU240_to_ne11pg2_trbilin.20240201.nc
map_ne11pg2_to_QU240_esmfnstod.20240201.nc
map_ne11pg2_to_QU240_ncoaave.20240201.nc
map_ne11pg2_to_QU240_ncoidw.20240201.nc
map_ne11pg2_to_QU240_traave.20240201.nc
map_ne11pg2_to_QU240_trbilin.20240201.nc

http://nco.sf.net/nco.html#alg_lst
http://nco.sf.net/nco.html#ncremap

D. All NCO operators now support the draft CF Convention on encoding
metadata that describes lossy compression applied to the dataset.
See https://github.com/cf-convention/cf-conventions/issues/403.
For example, all variables quantized by NCO now receive attributes
that contain the level of quantization and that point to a
container variable that describes the algorithm:

% ncks -O -7 --cmp='btr|shf|zst' in.nc foo.nc
% ncks -m -v ts foo.nc
 char compression_info ;
   char compression_info ;
   compression_info:family = "quantize" ;
   compression_info:algorithm = "BitRound" ;
   compression_info:implementation = "libnetcdf version 4.9.3-development" ;
 float ts(time,lat,lon) ;
      ts:standard_name = "surface_temperature" ;
      ts:lossy_compression = "compression_info" ;
      ts:lossy_compression_nsb = 9 ;

http://nco.sf.net/nco.html#qnt

E. ncks supports a new flag, --chk_bnd, that reports whether all
coordinate variables in a file contain associated "bounds" variables. 
This check complies with CF Conventions and with NASA's Dataset
Interoperability Working Group (DIWG) recommendations:
$ ncks --chk_bnd ~/nco/data/in.nc
ncks: WARNING nco_chk_bnd() reports coordinate Lat does not contain "bounds" attribute
ncks: WARNING nco_chk_bnd() reports coordinate Lon does not contain "bounds" attribute
ncks: INFO nco_chk_bnd() reports total number of coordinates without "bounds" attribute is 2
http://nco.sf.net/nco.htlm/chk_bnd

F. ncremap supports the TempestRemap trfv2 algorithm, a 2nd order FV
reconstruction, that is cell-integrated on the target grid.
ncremap --alg_typ=trfv2 -s grd_src.nc -g grd_dst.nc --map=map.nc
http://nco.sf.net/nco.htlm/trfv2

BUG FIXES:
   
A. ncclimo fixes an error in the climatology_bounds variable
output for the climatological December file in DJF-winter mode
climos. JFD-winter mode climos (used by most people) are unaffected.
There is no workaround. The solution is to upgrade. 
ncclimo --wnt_md=djf -c $caseid -s 2000 -e 2024 ...

Full release statement at http://nco.sf.net/ANNOUNCE
    
KNOWN PROBLEMS DUE TO NCO:

This section of ANNOUNCE reports and reminds users of the
existence and severity of known, not yet fixed, problems. 
These problems occur with NCO 5.2.0 built/tested under
MacOS 14.2.1 with netCDF 4.9.3-dev on HDF5 1.14.3 and with
Linux FC38 with netCDF 4.9.2 on HDF5 1.14.1.

A. NOT YET FIXED (NCO problem)
   Correctly read arrays of NC_STRING with embedded delimiters in ncatted arguments

   Demonstration:
   ncatted -D 5 -O -a new_string_att,att_var,c,sng,"list","of","str,ings" ~/nco/data/in_4.nc ~/foo.nc
   ncks -m -C -v att_var ~/foo.nc

   20130724: Verified problem still exists
   TODO nco1102
   Cause: NCO parsing of ncatted arguments is not sophisticated
   enough to handle arrays of NC_STRINGS with embedded delimiters.

B. NOT YET FIXED (NCO problem?)
   ncra/ncrcat (not ncks) hyperslabbing can fail on variables with multiple record dimensions

   Demonstration:
   ncrcat -O -d time,0 ~/nco/data/mrd.nc ~/foo.nc

   20140826: Verified problem still exists
   20140619: Problem reported by rmla
   Cause: Unsure. Maybe ncra.c loop structure not amenable to MRD?
   Workaround: Convert to fixed dimensions then hyperslab

KNOWN PROBLEMS DUE TO BASE LIBRARIES/PROTOCOLS:

A. NOT YET FIXED (netCDF4 or HDF5 problem?)
   Specifying strided hyperslab on large netCDF4 datasets leads
   to slowdown or failure with recent netCDF versions.

   Demonstration with NCO <= 4.4.5:
   time ncks -O -d time,0,,12 ~/ET_2000-01_2001-12.nc ~/foo.nc
   Demonstration with NCL:
   time ncl < ~/nco/data/ncl.ncl   
   20140718: Problem reported by Parker Norton
   20140826: Verified problem still exists
   20140930: Finish NCO workaround for problem
   20190201: Possibly this problem was fixed in netCDF 4.6.2 by https://github.com/Unidata/netcdf-c/pull/1001
   Cause: Slow algorithm in nc_var_gets()?
   Workaround #1: Use NCO 4.4.6 or later (avoids nc_var_gets())
   Workaround #2: Convert file to netCDF3 first, then use stride
   Workaround #3: Compile NCO with netCDF >= 4.6.2

B. NOT YET FIXED (netCDF4 library bug)
   Simultaneously renaming multiple dimensions in netCDF4 file can corrupt output

   Demonstration:
   ncrename -O -d lev,z -d lat,y -d lon,x ~/nco/data/in_grp.nc ~/foo.nc # Completes but produces unreadable file foo.nc
   ncks -v one ~/foo.nc

   20150922: Confirmed problem reported by Isabelle Dast, reported to Unidata
   20150924: Unidata confirmed problem
   20160212: Verified problem still exists in netCDF library
   20160512: Ditto
   20161028: Verified problem still exists with netCDF 4.4.1
   20170323: Verified problem still exists with netCDF 4.4.2-development
   20170323: https://github.com/Unidata/netcdf-c/issues/381
   20171102: Verified problem still exists with netCDF 4.5.1-development
   20171107: https://github.com/Unidata/netcdf-c/issues/597
   20190202: Progress has recently been made in netCDF 4.6.3-development
   More details: http://nco.sf.net/nco.html#ncrename_crd

C. NOT YET FIXED (would require DAP protocol change?)
   Unable to retrieve contents of variables including period '.' in name
   Periods are legal characters in netCDF variable names.
   Metadata are returned successfully, data are not.
   DAP non-transparency: Works locally, fails through DAP server.

   Demonstration:
   ncks -O -C -D 3 -v var_nm.dot -p http://thredds-test.ucar.edu/thredds/dodsC/testdods in.nc # Fails to find variable

   20130724: Verified problem still exists. 
   Stopped testing because inclusion of var_nm.dot broke all test scripts.
   NB: Hard to fix since DAP interprets '.' as structure delimiter in HTTP query string.

   Bug tracking: https://www.unidata.ucar.edu/jira/browse/NCF-47

D. NOT YET FIXED (would require DAP protocol change)
   Correctly read scalar characters over DAP.
   DAP non-transparency: Works locally, fails through DAP server.
   Problem, IMHO, is with DAP definition/protocol

   Demonstration:
   ncks -O -D 1 -H -C -m --md5_dgs -v md5_a -p http://thredds-test.ucar.edu/thredds/dodsC/testdods in.nc

   20120801: Verified problem still exists
   Bug report not filed
   Cause: DAP translates scalar characters into 64-element (this
   dimension is user-configurable, but still...), NUL-terminated
   strings so MD5 agreement fails 

"Sticky" reminders:

A. Reminder that NCO works on most HDF4 and HDF5 datasets, e.g., 
   HDF4: AMSR MERRA MODIS ...
   HDF5: GLAS ICESat Mabel SBUV ...
   HDF-EOS5: AURA HIRDLS OMI ...

B. Pre-built executables for many OS's at:
   http://nco.sf.net#bnr

