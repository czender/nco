$Header$ -*-text-*-

Let netCDF Operators NCO version 5.0.2 join your stack.

http://nco.sf.net (Homepage, Mailing lists, Help)
http://github.com/nco (Source Code, Issues, Releases, Developers)

What's new?
Version 5.0.2 contains significant new features and few minor fixes. 
ncclimo now splits timeseries into variables specified by regular
expressions. ncremap now supports the MOAB parallel interface to the
TempestRemap (TR) weight-generation libraries for 1D FV->FV grids.
The regridder and all quantization algorithms (including BitGroom)
have been refactored to treat NC_FILL_FLOAT/DOUBLE as the _FillValue
if no other _FillValue has been explicitly set.

Work on NCO 5.0.3 has commenced and will improve ncremap support
for MOAB, incorporate new MOAB improvements, and improve quantization
metadata and algorithms.

Enjoy,
Charlie

NEW FEATURES (full details always in ChangeLog):

A. ncclimo now expands variable lists that contain regular
   expressions (RX). Previously the splitter would aggregate
   all variables specified by an RX into a single timeseries file.
   Now the splitter places every variable into its own file.
   Thus using an RX produces the same timeseries files as explicitly
   specifying every variable. There is no change in the behavior
   of climo mode; it continues to put all variables in one file.
   ncclimo --var_lst=_2DMS.? in*.nc
   ncclimo --var_lst=_2DMS.? --var_xtr=area in*.nc
   Both commands use an RX in a variable list. The second command
   explicitly adds the 'area' variable to all output timeseries.
   The improved functionality should be especially useful to analyze 
   datasets with large numbers of tracers/species.
   Thanks to Qi Tang of PNNL for suggesting this feature.

A. ncremap now supports the MOAB parallel interface to the
   TempestRemap (TR) weight-generation libraries for 1D FV->FV grids. 
   ncremap will invoke mbtempest in parallel mode whenever the user
   requests a TR algorithm (e.g., --alg_typ=fv2fv_flx) and,
   additionally, specifies the number of MPI tasks-per-node with
   --mpi_nb=<mpi_nbr>: 
   ncremap 		--alg_typ=fv2fv_flx ... --map=map.nc # TR
   ncremap --mpi_nbr=24 --alg_typ=fv2fv_flx ... --map=map.nc # MOAB
   BTW, the same convention applies to MPI-enabled ERWG:
   ncremap 		--alg_typ=aave ... --map=map.nc # ESMF
   ncremap --mpi_nbr=24	--alg_typ=aave ... --map=map.nc # Parallel ESMF
   ncremap automatically uses mbconvert to convert SCRIP and Exodus 
   gridfiles (based on their file suffix) to MOAB .h5m format.
   It then uses mbpart to partition the MOAB grids, and then
   calls mbtempest. Two ncremap options specific to mbtempest are
   available to configure this workflow. The intersection algorithm
   can be set with --nsx_alg=advfront|kdtree (default is kdtree).
   Set the partition number for mbpart with --prt_nbr=<prt_nbr>.
   The partition number must be a multiple of mpi_nbr and by default
   prt_nbr=mpi_nbr. 
   ncremap --mpi_nbr=24 --nsx_alg=advfront --alg_typ=fv2fv_flx ...
   ncremap --mpi_nbr=24 --prt_nbr=48 --alg_typ=fv2fv_flx ...
   ncremap --mpi_nbr=24 --prt_nbr=48 --alg_typ=fv2fv_flx ...
   Limitations that MOAB anticipates removing in future releases:
   Currently MOAB is only trustworthy for the fv2fv_flx algorithm.
   High order and spectral element maps require more work in MOAB.
   Currently mbtempest only generates map-files that regrid to rank 1
   (unstructured) grids.  mbtempest "unrolls" any rank 2 (e.g.,
   latxlon) destination grid into its rank 1 equivalent.
   Users seeking to regrid to rank 2 grids can manually alter the
   MOAB-generated mapfile with something like:
   ncks -O -x -v dst_grid_dims ~/map.nc ~/map_fix.nc
   ncap2 -O -s 'defdim("dst_grid_dims",2);dst_grid_dims($dst_grid_dims)={256,129};' ~/map_tmp.nc ~/map_fix.nc
   Replace 256,129 by the lon,lat (Fortran order!) of your grid.
   The resulting map-file, map_fix.nc, will almost regrid as intended.
   The regridded output will have curvilinear coordinates (e.g,
   lat(lat,lon)) instead of rectangular coordinates (e.g., lat(lat)),
   and the coordinate "bounds" variables (e.g., lat_bnds) will not be
   correct and may cause plotting issues at poles and Greenwich.
   Nevertheless, the weights are correct and of unsurpassed accuracy.
   MOAB anticipates supporting rank 2 mapfiles and TR high-order and 
   spectral element algorithms in the future.
   This initial NCO support gives the opportunity to adopt ncremap
   to generate FV->FV mapfiles with 1D destination grids, an important
   class of regridding problems for model coupling purposes. 
   We welcome suggestions for new/improved options/features.
   Due to its complexity, only MOAB insalled via Conda is supported.
   Thanks to Vijay Mahadevan of ANL for his help with MOAB.
   http://nco.sf.net/nco.html#tr
   http://nco.sf.net/nco.html#moab

A. Bit-Adjustment-Algorithms (BAAs) for lossy quantization
   (e.g., BitGrooming) now only quantize the values NC_FILL_FLOAT or
   NC_FILL_DOUBLE for float and double variables, respectively, when
   the _FillValue attribute has been set to some other value.
   Previously all BAAs always quantized NC_FILL_FLOAT or
   NC_FILL_DOUBLE unless they were explicitly set as _FillValue.
   Thanks to Ed Hartnett of NOAA for this suggestion.

A. Similarly, the ncremap regridder and vertical interpolation
   routines now treat the values NC_FILL_FLOAT and NC_FILL_DOUBLE as
   missing values for float and double variables, respectively,
   unless their _FillValue has been explicitly set to some other
   value. Now datasets that never explicitly set a _FillValue 
   will be regridded/interpolated properly. 

A. Operators like ncks and ncrcat that utilize the UDUnits library
   will now report more thorough diagnostics when that library cannot
   be successfully opened, e.g., because the database file could not
   be found. This has been helpful in diagnosing the issues that
   underlie unexpected workflow failures that turn out to be due to
   incorrectly configured UDUnits environments. Thanks to Tom Vo of
   LLNL for helping uncover related issues.

A. ncremap now infers curvilinear grids from data files that include
   coordinates named west_east and south_north.
   Thanks to a StackOverflow user for suggesting this feature.

A. ncclimo now assumes the model name string in input files is 'eam'
   not 'cam'. The old behavior can be recovered by explicitly
   specifying ncclimo --mdl_nm=cam.

BUG FIXES:
   
A. ncclimo automatically turns-on splitter mode when clm_md=hfs
   and files are provided by globbing the input directory.
   Previously ncclimo would not enter splitter mode automatically
   under these circumstances. The workaround is to force splitter
   mode by specifying the --ypf=ypf option. The solution is to
   upgrade.

B. A minor change to OpenMP behavior now allows Intel compilers
   to build NCO from source (once again). This bug was introduced
   in NCO ~4.9.9 and affects only Intel compilers. The solution is to
   upgrade. Thanks to Matthew Thompson of GSFC for pointing this out.

C. ncclimo and ncremap now passes the option --mem=0 to srun
   on Cori at NERSC. Previously it passed the option --mem=20000,
   which could exhaust the available RAM at high-resolution.

Full release statement at http://nco.sf.net/ANNOUNCE
    
KNOWN PROBLEMS DUE TO NCO:

This section of ANNOUNCE reports and reminds users of the
existence and severity of known, not yet fixed, problems. 
These problems occur with NCO 5.0.2 built/tested under
MacOS 11.5 with netCDF 4.8.0 on HDF5 1.12.0 and with
Linux with netCDF 4.8.0 on HDF5 1.8.19.

A. NOT YET FIXED (NCO problem)
   Correctly read arrays of NC_STRING with embedded delimiters in ncatted arguments

   Demonstration:
   ncatted -D 5 -O -a new_string_att,att_var,c,sng,"list","of","str,ings" ~/nco/data/in_4.nc ~/foo.nc
   ncks -m -C -v att_var ~/foo.nc

   20130724: Verified problem still exists
   TODO nco1102
   Cause: NCO parsing of ncatted arguments is not sophisticated
   enough to handle arrays of NC_STRINGS with embedded delimiters.

B. NOT YET FIXED (NCO problem?)
   ncra/ncrcat (not ncks) hyperslabbing can fail on variables with multiple record dimensions

   Demonstration:
   ncrcat -O -d time,0 ~/nco/data/mrd.nc ~/foo.nc

   20140826: Verified problem still exists
   20140619: Problem reported by rmla
   Cause: Unsure. Maybe ncra.c loop structure not amenable to MRD?
   Workaround: Convert to fixed dimensions then hyperslab

KNOWN PROBLEMS DUE TO BASE LIBRARIES/PROTOCOLS:

A. NOT YET FIXED (netCDF4 or HDF5 problem?)
   Specifying strided hyperslab on large netCDF4 datasets leads
   to slowdown or failure with recent netCDF versions.

   Demonstration with NCO <= 4.4.5:
   time ncks -O -d time,0,,12 ~/ET_2000-01_2001-12.nc ~/foo.nc
   Demonstration with NCL:
   time ncl < ~/nco/data/ncl.ncl   
   20140718: Problem reported by Parker Norton
   20140826: Verified problem still exists
   20140930: Finish NCO workaround for problem
   20190201: Possibly this problem was fixed in netCDF 4.6.2 by https://github.com/Unidata/netcdf-c/pull/1001
   Cause: Slow algorithm in nc_var_gets()?
   Workaround #1: Use NCO 4.4.6 or later (avoids nc_var_gets())
   Workaround #2: Convert file to netCDF3 first, then use stride
   Workaround #3: Compile NCO with netCDF >= 4.6.2

B. NOT YET FIXED (netCDF4 library bug)
   Simultaneously renaming multiple dimensions in netCDF4 file can corrupt output

   Demonstration:
   ncrename -O -d lev,z -d lat,y -d lon,x ~/nco/data/in_grp.nc ~/foo.nc # Completes but produces unreadable file foo.nc
   ncks -v one ~/foo.nc

   20150922: Confirmed problem reported by Isabelle Dast, reported to Unidata
   20150924: Unidata confirmed problem
   20160212: Verified problem still exists in netCDF library
   20160512: Ditto
   20161028: Verified problem still exists with netCDF 4.4.1
   20170323: Verified problem still exists with netCDF 4.4.2-development
   20170323: https://github.com/Unidata/netcdf-c/issues/381
   20171102: Verified problem still exists with netCDF 4.5.1-development
   20171107: https://github.com/Unidata/netcdf-c/issues/597
   20190202: Progress has recently been made in netCDF 4.6.3-development
   More details: http://nco.sf.net/nco.html#ncrename_crd

C. NOT YET FIXED (would require DAP protocol change?)
   Unable to retrieve contents of variables including period '.' in name
   Periods are legal characters in netCDF variable names.
   Metadata are returned successfully, data are not.
   DAP non-transparency: Works locally, fails through DAP server.

   Demonstration:
   ncks -O -C -D 3 -v var_nm.dot -p http://thredds-test.ucar.edu/thredds/dodsC/testdods in.nc # Fails to find variable

   20130724: Verified problem still exists. 
   Stopped testing because inclusion of var_nm.dot broke all test scripts.
   NB: Hard to fix since DAP interprets '.' as structure delimiter in HTTP query string.

   Bug tracking: https://www.unidata.ucar.edu/jira/browse/NCF-47

D. NOT YET FIXED (would require DAP protocol change)
   Correctly read scalar characters over DAP.
   DAP non-transparency: Works locally, fails through DAP server.
   Problem, IMHO, is with DAP definition/protocol

   Demonstration:
   ncks -O -D 1 -H -C -m --md5_dgs -v md5_a -p http://thredds-test.ucar.edu/thredds/dodsC/testdods in.nc

   20120801: Verified problem still exists
   Bug report not filed
   Cause: DAP translates scalar characters into 64-element (this
   dimension is user-configurable, but still...), NUL-terminated
   strings so MD5 agreement fails 

"Sticky" reminders:

A. Reminder that NCO works on most HDF4 and HDF5 datasets, e.g., 
   HDF4: AMSR MERRA MODIS ...
   HDF5: GLAS ICESat Mabel SBUV ...
   HDF-EOS5: AURA HIRDLS OMI ...

B. Pre-built executables for many OS's at:
   http://nco.sf.net#bnr

